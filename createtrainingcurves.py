# -*- coding: utf-8 -*-
"""createTrainingCurves.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/114wQmZ4SoW-sO4phNObqUTr7Wt-hkSzc
"""

from buildandtrain-game import replay_buffer, dataset #replace -game for each game file
import gym
import matplotlib.pyplot as plt
import numpy as np
from matplotlib import animation
import random
import tensorflow as tf
from gym.wrappers import TimeLimit
from tf_agents.environments import suite_gym
from tf_agents.environments import suite_atari
from tf_agents.environments.atari_preprocessing import AtariPreprocessing
from tf_agents.environments.atari_wrappers import FrameStack4
from tf_agents.environments.tf_py_environment import TFPyEnvironment
from tf_agents.networks.q_network import QNetwork
from tf_agents.agents.dqn.dqn_agent import DqnAgent
from tf_agents.replay_buffers import tf_uniform_replay_buffer
from tf_agents.eval.metric_utils import log_metrics
import logging
from tf_agents.metrics import tf_metrics
from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver
from tf_agents.policies.random_tf_policy import RandomTFPolicy
from tf_agents.utils.common import function
import matplotlib as mpl
import matplotlib.animation as animation
import PIL
import os
import matplotlib.pyplot as plt

# ...
max_episode_steps=50000
environment_name = "Pong-v4"  # Change to Space Invaders
env = suite_atari.load(
    environment_name,
    gym_env_wrappers=[AtariPreprocessing, FrameStack4])
tf_env = TFPyEnvironment(env)

def compute_long_run_average_return(checkpoint_steps):
    checkpoint_returns = []
    iterator = iter(dataset)  # Define the iterator
    for step in checkpoint_steps:
        time_step = None
        policy_state = agent.collect_policy.get_initial_state(tf_env.batch_size)
        returns = []
        for _ in range(step):
            time_step, policy_state = collect_driver.run(time_step, policy_state)
            trajectories, _ = next(iterator)
            returns.append(trajectories.reward.numpy().mean())
        checkpoint_returns.append(sum(returns) / len(returns))
    return checkpoint_returns

checkpoint_steps = [500,1000,1500,2000,2500,3000,3500,4000,4500,5000]
checkpoint_returns = compute_long_run_average_return(checkpoint_steps)

# Plot the long-run average discounted reward
plt.figure(figsize=(8, 6))
plt.plot(checkpoint_steps, checkpoint_returns, marker='o')
plt.xlabel('Checkpoint Steps')
plt.ylabel('Long-Run Average Discounted Reward')
plt.title('Long-Run Average Discounted Reward at Checkpoints')
plt.tight_layout()
plt.show()

